{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "508_Assingment_5_1_Text_Mining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1hDk9hDvOH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9edb5d32-dc92-4f7f-82e1-848ea1e4e191"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#Change current working directory to gdrive\n",
        "%cd /gdrive\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_k0z66e38lG",
        "outputId": "54238984-0b59-4bd8-a476-77c082f6a6c1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer \n",
        "from nltk.stem import LancasterStemmer \n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMwGQK7KAd7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71948a8-e2bd-4de9-ed87-76c5233fbd7e"
      },
      "source": [
        "#Read files\n",
        "textfile = r'/gdrive/MyDrive/CIS508/Assignment_5/Problem_1_NLP/Comments.csv'\n",
        "textData = pd.read_csv(textfile) #creates a dataframe\n",
        "\n",
        "CustInfofile = r'/gdrive/MyDrive/CIS508/Assignment_5/Problem_1_NLP/Customers.csv'\n",
        "CustInfoData = pd.read_csv(CustInfofile)  #creates a dataframe\n",
        "\n",
        "print(textData.shape)\n",
        "print(CustInfoData.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 2)\n",
            "(2070, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWOTk6C1Ao45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209fbd48-3ae8-4e6d-c915-25b768f89a60"
      },
      "source": [
        "#Extract target column from Customer Info file\n",
        "X = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
        "y = CustInfoData[\"TARGET\"]\n",
        "                     \n",
        "print(X.shape)\n",
        "print(textData.shape)\n",
        "print(textData.head())\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 16)\n",
            "(2070, 2)\n",
            "     ID                                           Comments\n",
            "0  1309  Does not like the way the phone works. It is t...\n",
            "1  3556  Wanted to know the nearest store location. Wan...\n",
            "2  2230  Wants to know how to do text messaging. Referr...\n",
            "3  2312  Asked how to disable call waiting. referred hi...\n",
            "4  3327  Needs help learning how to use the phone. I su...\n",
            "0       Cancelled\n",
            "1         Current\n",
            "2         Current\n",
            "3         Current\n",
            "4       Cancelled\n",
            "          ...    \n",
            "2065    Cancelled\n",
            "2066    Cancelled\n",
            "2067    Cancelled\n",
            "2068    Cancelled\n",
            "2069    Cancelled\n",
            "Name: TARGET, Length: 2070, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAVmSg_E8cWz"
      },
      "source": [
        "Word Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuWYNz2Ep17l"
      },
      "source": [
        "#Tokenize - Split the sentences to lists of words\n",
        "textData['CommentsTokenized'] = textData['Comments'].apply(word_tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZrCq122evoIW",
        "outputId": "8faaf385-51b4-4a08-f6cf-b03ce9c745f9"
      },
      "source": [
        "textData"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Comments</th>\n",
              "      <th>CommentsTokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1309</td>\n",
              "      <td>Does not like the way the phone works. It is t...</td>\n",
              "      <td>[Does, not, like, the, way, the, phone, works,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3556</td>\n",
              "      <td>Wanted to know the nearest store location. Wan...</td>\n",
              "      <td>[Wanted, to, know, the, nearest, store, locati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2230</td>\n",
              "      <td>Wants to know how to do text messaging. Referr...</td>\n",
              "      <td>[Wants, to, know, how, to, do, text, messaging...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2312</td>\n",
              "      <td>Asked how to disable call waiting. referred hi...</td>\n",
              "      <td>[Asked, how, to, disable, call, waiting, ., re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3327</td>\n",
              "      <td>Needs help learning how to use the phone. I su...</td>\n",
              "      <td>[Needs, help, learning, how, to, use, the, pho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2065</th>\n",
              "      <td>3034</td>\n",
              "      <td>Needed help figuring out his bill. I explained...</td>\n",
              "      <td>[Needed, help, figuring, out, his, bill, ., I,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2066</th>\n",
              "      <td>271</td>\n",
              "      <td>He lost his phone and called to cancel service...</td>\n",
              "      <td>[He, lost, his, phone, and, called, to, cancel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2067</th>\n",
              "      <td>783</td>\n",
              "      <td>Lost the directions to phone and wants another...</td>\n",
              "      <td>[Lost, the, directions, to, phone, and, wants,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2068</th>\n",
              "      <td>1295</td>\n",
              "      <td>Wants to change address.</td>\n",
              "      <td>[Wants, to, change, address, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2069</th>\n",
              "      <td>1807</td>\n",
              "      <td>He lost his phone and called to cancel service...</td>\n",
              "      <td>[He, lost, his, phone, and, called, to, cancel...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2070 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        ID  ...                                  CommentsTokenized\n",
              "0     1309  ...  [Does, not, like, the, way, the, phone, works,...\n",
              "1     3556  ...  [Wanted, to, know, the, nearest, store, locati...\n",
              "2     2230  ...  [Wants, to, know, how, to, do, text, messaging...\n",
              "3     2312  ...  [Asked, how, to, disable, call, waiting, ., re...\n",
              "4     3327  ...  [Needs, help, learning, how, to, use, the, pho...\n",
              "...    ...  ...                                                ...\n",
              "2065  3034  ...  [Needed, help, figuring, out, his, bill, ., I,...\n",
              "2066   271  ...  [He, lost, his, phone, and, called, to, cancel...\n",
              "2067   783  ...  [Lost, the, directions, to, phone, and, wants,...\n",
              "2068  1295  ...                    [Wants, to, change, address, .]\n",
              "2069  1807  ...  [He, lost, his, phone, and, called, to, cancel...\n",
              "\n",
              "[2070 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-FSC5QJ8gFM"
      },
      "source": [
        "Stemmer experience"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYkr1rrM-dn4"
      },
      "source": [
        "TD_snow=textData.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeYXLU-u_v9R"
      },
      "source": [
        "# Use English stemmer.\"Snowball\"\n",
        "stem_snow = SnowballStemmer(\"english\")\n",
        "\n",
        "#Now do stemming  \n",
        "TD_snow['CommentsTokenizedStemmed'] = TD_snow['CommentsTokenized'].apply(lambda x: [stem_snow.stem(y) for y in x]) # Stem every word.\n",
        "#Drop Unnecessary Columns \n",
        "TD_snow=TD_snow.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "#Save\n",
        "#export_csv = TD_snow.to_csv(r'/gdrive/MyDrive/CIS508/Assignment_5/Problem_1_NLP/TD_snow.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sOnOlXTqHdpK",
        "outputId": "73f456e4-720a-4ae6-ad86-cccdea7c358d"
      },
      "source": [
        "TD_snow.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>CommentsTokenizedStemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1309</td>\n",
              "      <td>[doe, not, like, the, way, the, phone, work, ....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3556</td>\n",
              "      <td>[want, to, know, the, nearest, store, locat, ....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2230</td>\n",
              "      <td>[want, to, know, how, to, do, text, messag, .,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2312</td>\n",
              "      <td>[ask, how, to, disabl, call, wait, ., refer, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3327</td>\n",
              "      <td>[need, help, learn, how, to, use, the, phone, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ID                           CommentsTokenizedStemmed\n",
              "0  1309  [doe, not, like, the, way, the, phone, work, ....\n",
              "1  3556  [want, to, know, the, nearest, store, locat, ....\n",
              "2  2230  [want, to, know, how, to, do, text, messag, .,...\n",
              "3  2312  [ask, how, to, disabl, call, wait, ., refer, h...\n",
              "4  3327  [need, help, learn, how, to, use, the, phone, ..."
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isx5IfAxFzWq"
      },
      "source": [
        "TD_lan=textData.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMyF8PFd8RIC"
      },
      "source": [
        "# Use English stemmer.\"Lancaster\"\n",
        "stem_lan = LancasterStemmer()\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version, \n",
        "TD_lan['CommentsTokenizedStemmed'] = TD_lan['CommentsTokenized'].apply(lambda x: [stem_lan.stem(y) for y in x]) \n",
        "#Drop Unnecessary Columns \n",
        "TD_lan=TD_lan.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "#Save\n",
        "#export_csv = TD_lan.to_csv(r'/gdrive/MyDrive/CIS508/Assignment_5/Problem_1_NLP/TD_lan.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3soBEwJpHS00",
        "outputId": "f228e025-148b-401c-e7ec-312a4b42f38f"
      },
      "source": [
        "TD_lan.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>CommentsTokenizedStemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1309</td>\n",
              "      <td>[doe, not, lik, the, way, the, phon, work, ., ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3556</td>\n",
              "      <td>[want, to, know, the, nearest, stor, loc, ., w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2230</td>\n",
              "      <td>[want, to, know, how, to, do, text, mess, ., r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2312</td>\n",
              "      <td>[ask, how, to, dis, cal, wait, ., refer, him, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3327</td>\n",
              "      <td>[nee, help, learn, how, to, us, the, phon, ., ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ID                           CommentsTokenizedStemmed\n",
              "0  1309  [doe, not, lik, the, way, the, phon, work, ., ...\n",
              "1  3556  [want, to, know, the, nearest, stor, loc, ., w...\n",
              "2  2230  [want, to, know, how, to, do, text, mess, ., r...\n",
              "3  2312  [ask, how, to, dis, cal, wait, ., refer, him, ...\n",
              "4  3327  [nee, help, learn, how, to, us, the, phon, ., ..."
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gCRxWcHswS4",
        "outputId": "9caca066-24c5-4af5-b035-5c8b4d64dc05"
      },
      "source": [
        "print(stem_lan.stem('phone'))\n",
        "print(stem_snow.stem('phone'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phon\n",
            "phone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M07E7VW7_y0d"
      },
      "source": [
        "#Join stemmed strings : Snow Stemmer\n",
        "TD_snow['CommentsTokenizedStemmed'] = TD_snow['CommentsTokenizedStemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "#export_csv = TD_Snow.to_csv(r'/gdrive/MyDrive/CIS508/Assignment_5/Problem_1_NLP/TD-Joined.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGeyXmtE8lKt"
      },
      "source": [
        "Stop word "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRh6QmcTJwH7",
        "outputId": "4c35bc40-ebcb-4552-90e3-048549593543"
      },
      "source": [
        "#Stop word \n",
        "count_vect = CountVectorizer(stop_words='english',lowercase=False)\n",
        "TD_counts = count_vect.fit_transform(TD_snow.CommentsTokenizedStemmed)\n",
        "print(TD_counts.shape)\n",
        "print(TD_counts.dtype)\n",
        "print(count_vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 354)\n",
            "int64\n",
            "['3399', '3g', 'abysm', 'access', 'accessori', 'adapt', 'add', 'addit', 'additon', 'address', 'adit', 'adress', 'advertis', 'afraid', 'alway', 'angel', 'angri', 'ani', 'anoth', 'anyth', 'anytim', 'area', 'asap', 'ask', 'bad', 'basic', 'bateri', 'batteri', 'becaus', 'believ', 'better', 'bigger', 'book', 'bought', 'brain', 'bring', 'built', 'busi', 'button', 'buy', 'cancel', 'cancer', 'car', 'care', 'carrier', 'caus', 'cc', 'cell', 'certain', 'chang', 'charg', 'charger', 'check', 'chip', 'citi', 'claim', 'cleariti', 'cold', 'comapr', 'compani', 'compar', 'competit', 'complain', 'complaint', 'concept', 'connect', 'consisit', 'consist', 'constan', 'contact', 'continu', 'contract', 'correct', 'cost', 'coupl', 'cover', 'coverag', 'creat', 'credit', 'cstmer', 'cstmr', 'current', 'cust', 'custom', 'customr', 'date', 'day', 'dead', 'decent', 'defect', 'deo', 'did', 'die', 'differ', 'difficult', 'digiti', 'direct', 'disabl', 'doe', 'don', 'dont', 'drop', 'dure', 'easier', 'effect', 'encount', 'end', 'enemi', 'equip', 'everytim', 'everywher', 'evrey', 'exact', 'expect', 'expir', 'explain', 'facepl', 'fals', 'famili', 'featur', 'fed', 'figur', 'fine', 'fix', 'forev', 'forward', 'friend', 'function', 'furthermor', 'futur', 'gave', 'goat', 'good', 'great', 'gsm', 'handset', 'happi', 'hard', 'hate', 'hear', 'heard', 'help', 'higher', 'highway', 'hochi', 'hole', 'home', 'hope', 'horribl', 'hous', 'implement', 'improv', 'inadequ', 'includ', 'info', 'inform', 'ing', 'internet', 'intersect', 'issu', 'june', 'just', 'kid', 'kno', 'know', 'lame', 'later', 'lctn', 'learn', 'leroy', 'like', 'line', 'list', 'local', 'locat', 'locatn', 'long', 'los', 'lost', 'lot', 'love', 'major', 'make', 'manag', 'mani', 'manual', 'market', 'mean', 'messag', 'metropolitian', 'minut', 'misl', 'mistak', 'model', 'momma', 'mr', 'napeleon', 'near', 'nearest', 'need', 'network', 'new', 'news', 'notic', 'number', 'numer', 'offer', 'old', 'om', 'open', 'option', 'ori', 'ot', 'outbound', 'pass', 'pay', 'pda', 'peopl', 'perform', 'person', 'phone', 'piec', 'plan', 'pleas', 'point', 'polici', 'poor', 'possibl', 'probabl', 'problem', 'proper', 'provid', 'provis', 'purpos', 'rate', 'rater', 'realiz', 'realli', 'reason', 'receiv', 'recept', 'recption', 'reenter', 'refer', 'relat', 'rep', 'replac', 'respect', 'result', 'rid', 'right', 'ring', 'roam', 'roll', 'rubbish', 'rude', 'said', 'sale', 'say', 'screen', 'self', 'send', 'servic', 'shitti', 'shut', 'sign', 'signal', 'signific', 'simm', 'simpli', 'sinc', 'site', 'slow', 'sold', 'someon', 'sometim', 'soon', 'speak', 'speed', 'start', 'static', 'stole', 'store', 'stuff', 'stupid', 'substant', 'subtract', 'suck', 'suggest', 'supervisor', 'support', 'sure', 'surpris', 'suspect', 'suspend', 'switch', 'teach', 'technic', 'tell', 'terribl', 'test', 'text', 'think', 'thought', 'ticket', 'till', 'time', 'tire', 'today', 'toilet', 'told', 'tone', 'tower', 'transeff', 'transf', 'transfer', 'travel', 'tri', 'trust', 'turn', 'uncomfort', 'understand', 'unhappi', 'unlimit', 'unreli', 'unwil', 'upset', 'usag', 'use', 'useless', 'valu', 'veri', 'vm', 'wa', 'wait', 'want', 'wast', 'way', 'weak', 'web', 'websit', 'week', 'whi', 'wife', 'wish', 'wll', 'wold', 'work', 'wors', 'worst', 'wrong', 'xvyx', 'year', 'york']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsPwCJO2J4KR"
      },
      "source": [
        "Term Document Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiBguQloljam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09886e72-e70a-4510-f20b-99ad54f7b685"
      },
      "source": [
        "#Change to DataFrame\n",
        "DF_TD_Counts=pd.DataFrame(TD_counts.toarray())\n",
        "print(DF_TD_Counts)\n",
        "export_csv = DF_TD_Counts.to_csv(r'/gdrive/MyDrive/CIS508/Assignment_5/Problem_1_NLP/TD_counts-TokenizedStemmed.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0    1    2    3    4    5    6    ...  347  348  349  350  351  352  353\n",
            "0       0    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "1       0    0    0    0    1    0    0  ...    0    0    0    0    0    0    0\n",
            "2       0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "3       0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "4       0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "2066    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "2067    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "2068    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "2069    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "\n",
            "[2070 rows x 354 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O3O60CUMqpD"
      },
      "source": [
        "TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd8TZYnAxQbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cf5dc6-8900-4124-cfbd-984373c51fec"
      },
      "source": [
        "#Compute TF-IDF Matrix\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_tfidf = tfidf_transformer.fit_transform(TD_counts)\n",
        "print(X_tfidf.shape)\n",
        "DF_TF_IDF=pd.DataFrame(X_tfidf.toarray())\n",
        "print(DF_TF_IDF)\n",
        "export_csv= DF_TF_IDF.to_csv(r'/gdrive/MyDrive/CIS508/Assignment_5/Problem_1_NLP/TFIDF_counts-TokenizedStemmed.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 354)\n",
            "      0    1    2    3        4    5    ...  348  349  350  351  352  353\n",
            "0     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1     0.0  0.0  0.0  0.0  0.27568  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4     0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "...   ...  ...  ...  ...      ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2066  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2067  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2068  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2069  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "\n",
            "[2070 rows x 354 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gdCHlrGGrxy"
      },
      "source": [
        "Combine Customer Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kbCS6jOGrX_",
        "outputId": "86d6792c-f5c6-45a5-97c6-54668e45c916"
      },
      "source": [
        "#Merge files\n",
        "combined=pd.concat([X, DF_TF_IDF], axis=1)\n",
        "\n",
        "print(CustInfoData.shape)\n",
        "print(X.shape)\n",
        "print(combined.shape)\n",
        "print(combined)\n",
        "export_csv= combined.to_csv(r'/gdrive/MyDrive/CIS508/Assignment_5/Problem_1_NLP/Combined-Cust+TFIDF+SelectedFeatures.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 17)\n",
            "(2070, 16)\n",
            "(2070, 370)\n",
            "        ID Sex Status  Children  Est_Income  ...  349  350  351  352  353\n",
            "0        1   F      S         1    38000.00  ...  0.0  0.0  0.0  0.0  0.0\n",
            "1        6   M      M         2    29616.00  ...  0.0  0.0  0.0  0.0  0.0\n",
            "2        8   M      M         0    19732.80  ...  0.0  0.0  0.0  0.0  0.0\n",
            "3       11   M      S         2       96.33  ...  0.0  0.0  0.0  0.0  0.0\n",
            "4       14   F      M         2    52004.80  ...  0.0  0.0  0.0  0.0  0.0\n",
            "...    ...  ..    ...       ...         ...  ...  ...  ...  ...  ...  ...\n",
            "2065  3821   F      S         0    78851.30  ...  0.0  0.0  0.0  0.0  0.0\n",
            "2066  3822   F      S         1    17540.70  ...  0.0  0.0  0.0  0.0  0.0\n",
            "2067  3823   F      M         0    83891.90  ...  0.0  0.0  0.0  0.0  0.0\n",
            "2068  3824   F      M         2    28220.80  ...  0.0  0.0  0.0  0.0  0.0\n",
            "2069  3825   F      S         0    28589.10  ...  0.0  0.0  0.0  0.0  0.0\n",
            "\n",
            "[2070 rows x 370 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peX_JEBMG1Zl"
      },
      "source": [
        "One Hot encording"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQR2HrtRG0xZ",
        "outputId": "6fea4201-73fb-42e9-a0f8-92ae0fd553b5"
      },
      "source": [
        "#Do one Hot encoding for categorical features\n",
        "X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n",
        "combined_train = pd.get_dummies(combined,columns=X_cat)\n",
        "print(combined_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ID  ...  LongDistanceBilltype_Standard\n",
            "0        1  ...                              0\n",
            "1        6  ...                              1\n",
            "2        8  ...                              1\n",
            "3       11  ...                              1\n",
            "4       14  ...                              0\n",
            "...    ...  ...                            ...\n",
            "2065  3821  ...                              1\n",
            "2066  3822  ...                              1\n",
            "2067  3823  ...                              1\n",
            "2068  3824  ...                              1\n",
            "2069  3825  ...                              1\n",
            "\n",
            "[2070 rows x 378 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "kIlvf90GLXO9",
        "outputId": "674cf2e6-346f-4d6b-c0d6-f13a5907c60c"
      },
      "source": [
        "combined_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Children</th>\n",
              "      <th>Est_Income</th>\n",
              "      <th>Usage</th>\n",
              "      <th>Age</th>\n",
              "      <th>RatePlan</th>\n",
              "      <th>LongDistance</th>\n",
              "      <th>International</th>\n",
              "      <th>Local</th>\n",
              "      <th>Dropped</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>...</th>\n",
              "      <th>328</th>\n",
              "      <th>329</th>\n",
              "      <th>330</th>\n",
              "      <th>331</th>\n",
              "      <th>332</th>\n",
              "      <th>333</th>\n",
              "      <th>334</th>\n",
              "      <th>335</th>\n",
              "      <th>336</th>\n",
              "      <th>337</th>\n",
              "      <th>338</th>\n",
              "      <th>339</th>\n",
              "      <th>340</th>\n",
              "      <th>341</th>\n",
              "      <th>342</th>\n",
              "      <th>343</th>\n",
              "      <th>344</th>\n",
              "      <th>345</th>\n",
              "      <th>346</th>\n",
              "      <th>347</th>\n",
              "      <th>348</th>\n",
              "      <th>349</th>\n",
              "      <th>350</th>\n",
              "      <th>351</th>\n",
              "      <th>352</th>\n",
              "      <th>353</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th>Sex_M</th>\n",
              "      <th>Status_D</th>\n",
              "      <th>Status_M</th>\n",
              "      <th>Status_S</th>\n",
              "      <th>Car_Owner_N</th>\n",
              "      <th>Car_Owner_Y</th>\n",
              "      <th>Paymethod_Auto</th>\n",
              "      <th>Paymethod_CC</th>\n",
              "      <th>Paymethod_CH</th>\n",
              "      <th>LocalBilltype_Budget</th>\n",
              "      <th>LocalBilltype_FreeLocal</th>\n",
              "      <th>LongDistanceBilltype_Intnl_discount</th>\n",
              "      <th>LongDistanceBilltype_Standard</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38000.00</td>\n",
              "      <td>229.64</td>\n",
              "      <td>24.393333</td>\n",
              "      <td>3</td>\n",
              "      <td>23.56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.08</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.388928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209678</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>29616.00</td>\n",
              "      <td>75.29</td>\n",
              "      <td>49.426667</td>\n",
              "      <td>2</td>\n",
              "      <td>29.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.27568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.708478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312065</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>19732.80</td>\n",
              "      <td>47.25</td>\n",
              "      <td>50.673333</td>\n",
              "      <td>3</td>\n",
              "      <td>24.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.195324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.567289</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>96.33</td>\n",
              "      <td>59.01</td>\n",
              "      <td>56.473333</td>\n",
              "      <td>1</td>\n",
              "      <td>26.13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.88</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352868</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.480064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333825</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>52004.80</td>\n",
              "      <td>28.14</td>\n",
              "      <td>25.140000</td>\n",
              "      <td>1</td>\n",
              "      <td>5.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.11</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.348322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 378 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  ...  LongDistanceBilltype_Standard\n",
              "0   1  ...                              0\n",
              "1   6  ...                              1\n",
              "2   8  ...                              1\n",
              "3  11  ...                              1\n",
              "4  14  ...                              0\n",
              "\n",
              "[5 rows x 378 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP_UpUdiG5me"
      },
      "source": [
        "Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo86DFlkIA4T"
      },
      "source": [
        "1. Filter Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Hq_0kWzvaI"
      },
      "source": [
        "trainset=combined_train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2owIUD6_eYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b707b1-0416-4bc6-d9bd-51c50ad8c419"
      },
      "source": [
        "#Suppose, we select 50 features with top  Fisher scores\n",
        "selector = SelectKBest(k=50)\n",
        "combined_train_K50 = selector.fit_transform(trainset,y) \n",
        "feature_names_out = selector.get_support(indices=True) \n",
        "combined_train_K50_SelectedFeatures= pd.DataFrame(combined_train_K50)\n",
        "\n",
        "print(\"=== Top 50 Features ===\")\n",
        "print(combined_train_K50_SelectedFeatures)\n",
        "combined_train_K50.shape\n",
        "\n",
        "\n",
        "#Suppose, we select 100 features with top Fisher scores\n",
        "trainset=combined_train.copy()\n",
        "selector = SelectKBest(k=100)\n",
        "combined_train_K100 = selector.fit_transform(trainset,y) \n",
        "feature_names_out = selector.get_support(indices=True) \n",
        "combined_train_K100_SelectedFeatures= pd.DataFrame(combined_train_K100)\n",
        "\n",
        "print(\"=== Top 100 Features ===\")\n",
        "print(combined_train_K100_SelectedFeatures)\n",
        "combined_train_K100.shape\n",
        "\n",
        "\n",
        "#Suppose, we select 150 features with top Fisher scores\n",
        "trainset=combined_train.copy()\n",
        "selector = SelectKBest(k=150)\n",
        "combined_train_K150 = selector.fit_transform(trainset,y)\n",
        "feature_names_out = selector.get_support(indices=True)\n",
        "combined_train_K150_SelectedFeatures= pd.DataFrame(combined_train_K150)\n",
        "\n",
        "print(\"=== Top 150 Features ===\")\n",
        "print(combined_train_K150_SelectedFeatures)\n",
        "combined_train_K150.shape\n",
        "\n",
        "#Suppose, we select 200 features with top Fisher scores\n",
        "trainset=combined_train.copy()\n",
        "selector = SelectKBest(k=200)\n",
        "combined_train_K200 = selector.fit_transform(trainset,y)\n",
        "feature_names_out = selector.get_support(indices=True) \n",
        "combined_train_K200_SelectedFeatures= pd.DataFrame(combined_train_K200)\n",
        "\n",
        "print(\"=== Top 200 Features ===\")\n",
        "print(combined_train_K200_SelectedFeatures)\n",
        "combined_train_K200.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Top 50 Features ===\n",
            "       0         1       2      3     4       5   ...   44   45   46   47   48   49\n",
            "0     1.0  38000.00  229.64  23.56  0.00  206.08  ...  0.0  1.0  0.0  1.0  1.0  0.0\n",
            "1     2.0  29616.00   75.29  29.78  0.00   45.50  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2     0.0  19732.80   47.25  24.81  0.00   22.44  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "3     2.0     96.33   59.01  26.13  0.00   32.88  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "4     2.0  52004.80   28.14   5.03  0.00   23.11  ...  1.0  0.0  0.0  0.0  1.0  0.0\n",
            "...   ...       ...     ...    ...   ...     ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.0  78851.30   29.04   0.37  0.00   28.66  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "2066  1.0  17540.70   36.20  22.17  0.57   13.45  ...  0.0  1.0  1.0  0.0  0.0  1.0\n",
            "2067  0.0  83891.90   74.40  28.92  0.00   45.47  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2068  2.0  28220.80   38.95  26.49  0.00   12.46  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "2069  0.0  28589.10  100.28  13.19  0.00   87.09  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "\n",
            "[2070 rows x 50 columns]\n",
            "=== Top 100 Features ===\n",
            "       0         1       2      3     4       5   ...   94   95   96   97   98   99\n",
            "0     1.0  38000.00  229.64  23.56  0.00  206.08  ...  0.0  1.0  0.0  1.0  1.0  0.0\n",
            "1     2.0  29616.00   75.29  29.78  0.00   45.50  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2     0.0  19732.80   47.25  24.81  0.00   22.44  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "3     2.0     96.33   59.01  26.13  0.00   32.88  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "4     2.0  52004.80   28.14   5.03  0.00   23.11  ...  1.0  0.0  0.0  0.0  1.0  0.0\n",
            "...   ...       ...     ...    ...   ...     ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.0  78851.30   29.04   0.37  0.00   28.66  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "2066  1.0  17540.70   36.20  22.17  0.57   13.45  ...  0.0  1.0  1.0  0.0  0.0  1.0\n",
            "2067  0.0  83891.90   74.40  28.92  0.00   45.47  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2068  2.0  28220.80   38.95  26.49  0.00   12.46  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "2069  0.0  28589.10  100.28  13.19  0.00   87.09  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "\n",
            "[2070 rows x 100 columns]\n",
            "=== Top 150 Features ===\n",
            "      0         1       2    3      4     5    ...  144  145  146  147  148  149\n",
            "0     1.0  38000.00  229.64  3.0  23.56  0.00  ...  0.0  1.0  0.0  1.0  1.0  0.0\n",
            "1     2.0  29616.00   75.29  2.0  29.78  0.00  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2     0.0  19732.80   47.25  3.0  24.81  0.00  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "3     2.0     96.33   59.01  1.0  26.13  0.00  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "4     2.0  52004.80   28.14  1.0   5.03  0.00  ...  1.0  0.0  0.0  0.0  1.0  0.0\n",
            "...   ...       ...     ...  ...    ...   ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.0  78851.30   29.04  4.0   0.37  0.00  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "2066  1.0  17540.70   36.20  1.0  22.17  0.57  ...  0.0  1.0  1.0  0.0  0.0  1.0\n",
            "2067  0.0  83891.90   74.40  4.0  28.92  0.00  ...  1.0  0.0  0.0  0.0  0.0  1.0\n",
            "2068  2.0  28220.80   38.95  4.0  26.49  0.00  ...  1.0  0.0  0.0  1.0  0.0  1.0\n",
            "2069  0.0  28589.10  100.28  3.0  13.19  0.00  ...  0.0  1.0  0.0  1.0  0.0  1.0\n",
            "\n",
            "[2070 rows x 150 columns]\n",
            "=== Top 200 Features ===\n",
            "      0         1       2          3    4    ...  195  196  197  198  199\n",
            "0     1.0  38000.00  229.64  24.393333  3.0  ...  1.0  0.0  1.0  1.0  0.0\n",
            "1     2.0  29616.00   75.29  49.426667  2.0  ...  0.0  0.0  0.0  0.0  1.0\n",
            "2     0.0  19732.80   47.25  50.673333  3.0  ...  0.0  0.0  1.0  0.0  1.0\n",
            "3     2.0     96.33   59.01  56.473333  1.0  ...  1.0  0.0  1.0  0.0  1.0\n",
            "4     2.0  52004.80   28.14  25.140000  1.0  ...  0.0  0.0  0.0  1.0  0.0\n",
            "...   ...       ...     ...        ...  ...  ...  ...  ...  ...  ...  ...\n",
            "2065  0.0  78851.30   29.04  48.373333  4.0  ...  1.0  0.0  1.0  0.0  1.0\n",
            "2066  1.0  17540.70   36.20  62.786667  1.0  ...  1.0  1.0  0.0  0.0  1.0\n",
            "2067  0.0  83891.90   74.40  61.020000  4.0  ...  0.0  0.0  0.0  0.0  1.0\n",
            "2068  2.0  28220.80   38.95  38.766667  4.0  ...  0.0  0.0  1.0  0.0  1.0\n",
            "2069  0.0  28589.10  100.28  15.600000  3.0  ...  1.0  0.0  1.0  0.0  1.0\n",
            "\n",
            "[2070 rows x 200 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2070, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBbVgx6W1hvO",
        "outputId": "e68555f7-3339-4364-d37a-6c935b046f68"
      },
      "source": [
        "combined_train.shape\n",
        "print(feature_names_out)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1   2   3   4   5   6   7   8   9  10  12  13  14  16  17  19  20  21\n",
            "  24  26  27  29  30  33  34  35  36  37  39  40  41  45  46  49  53  54\n",
            "  56  57  58  59  60  61  62  65  66  67  70  71  72  74  76  77  80  82\n",
            "  83  88  89  90  91  92  93  94  97  98 101 102 104 105 109 116 119 124\n",
            " 125 128 130 131 135 136 138 140 141 142 143 145 147 148 149 151 154 155\n",
            " 158 159 161 164 166 167 168 170 171 174 176 177 178 180 182 183 184 185\n",
            " 186 192 193 196 200 203 204 207 208 211 214 215 216 218 219 221 222 223\n",
            " 226 227 230 231 232 234 238 239 240 244 245 248 249 254 255 258 259 264\n",
            " 266 267 268 269 270 271 272 274 276 277 282 283 287 288 290 293 296 297\n",
            " 298 299 305 306 312 317 322 323 325 328 329 330 331 333 335 337 338 341\n",
            " 342 343 346 348 350 351 352 354 358 360 361 362 364 365 367 368 371 372\n",
            " 376 377]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdRDvSue177O",
        "outputId": "e98a2bbc-9948-4372-cd72-c88c4dafcae6"
      },
      "source": [
        "#Construct classifiers to test candidate feature selection subgroups\n",
        "#Gradient boosting Classifier\n",
        "\n",
        "\n",
        "gb_K50= GradientBoostingClassifier().fit(combined_train_K50_SelectedFeatures,y)\n",
        "clf_cv_score = cross_val_score(gb_K50, combined_train_K50_SelectedFeatures,y, cv=20, scoring=\"accuracy\")\n",
        "\n",
        "print(\"=== All Accuracy Scores ===\")\n",
        "print(clf_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean Accuracy Score ===\")\n",
        "print(\"Mean Accuracy Score - ON Text: \",clf_cv_score.mean())\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "gb_K100= GradientBoostingClassifier().fit(combined_train_K100_SelectedFeatures, y)\n",
        "clf_cv_score = cross_val_score(gb_K100, combined_train_K100_SelectedFeatures, y, cv=20, scoring=\"accuracy\")\n",
        "\n",
        "print(\"=== All Accuracy Scores ===\")\n",
        "print(clf_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean Accuracy Score ===\")\n",
        "print(\"Mean Accuracy Score - ON Text: \",clf_cv_score.mean())\n",
        "print('\\n')\n",
        "\n",
        "gb_K150= GradientBoostingClassifier().fit(combined_train_K150_SelectedFeatures, y)\n",
        "clf_cv_score = cross_val_score(gb_K150, combined_train_K150_SelectedFeatures, y, cv=20, scoring=\"accuracy\")\n",
        "\n",
        "print(\"=== All Accuracy Scores ===\")\n",
        "print(clf_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean Accuracy Score ===\")\n",
        "print(\"Mean Accuracy Score - ON Text: \",clf_cv_score.mean())\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "gb_K200= GradientBoostingClassifier().fit(combined_train_K200_SelectedFeatures, y)\n",
        "clf_cv_score = cross_val_score(gb_K150, combined_train_K200_SelectedFeatures, y, cv=20, scoring=\"accuracy\")\n",
        "\n",
        "print(\"=== All Accuracy Scores ===\")\n",
        "print(clf_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean Accuracy Score ===\")\n",
        "print(\"Mean Accuracy Score - ON Text: \",clf_cv_score.mean())\n",
        "print('\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== All Accuracy Scores ===\n",
            "[0.84615385 0.84615385 0.81730769 0.875      0.85576923 0.85576923\n",
            " 0.88461538 0.77884615 0.81730769 0.90384615 0.90291262 0.87378641\n",
            " 0.94174757 0.81553398 0.86407767 0.84466019 0.91262136 0.9223301\n",
            " 0.83495146 0.86407767]\n",
            "\n",
            "\n",
            "=== Mean Accuracy Score ===\n",
            "Mean Accuracy Score - ON Text:  0.8628734129947722\n",
            "\n",
            "\n",
            "=== All Accuracy Scores ===\n",
            "[0.85576923 0.84615385 0.81730769 0.875      0.83653846 0.86538462\n",
            " 0.875      0.79807692 0.82692308 0.89423077 0.91262136 0.88349515\n",
            " 0.94174757 0.7961165  0.88349515 0.82524272 0.90291262 0.9223301\n",
            " 0.83495146 0.85436893]\n",
            "\n",
            "\n",
            "=== Mean Accuracy Score ===\n",
            "Mean Accuracy Score - ON Text:  0.8623833084391338\n",
            "\n",
            "\n",
            "=== All Accuracy Scores ===\n",
            "[0.85576923 0.85576923 0.82692308 0.875      0.84615385 0.83653846\n",
            " 0.88461538 0.76923077 0.84615385 0.90384615 0.9223301  0.90291262\n",
            " 0.94174757 0.83495146 0.88349515 0.84466019 0.9223301  0.91262136\n",
            " 0.84466019 0.89320388]\n",
            "\n",
            "\n",
            "=== Mean Accuracy Score ===\n",
            "Mean Accuracy Score - ON Text:  0.8701456310679612\n",
            "\n",
            "\n",
            "=== All Accuracy Scores ===\n",
            "[0.875      0.88461538 0.83653846 0.88461538 0.86538462 0.84615385\n",
            " 0.89423077 0.80769231 0.85576923 0.89423077 0.91262136 0.89320388\n",
            " 0.93203883 0.81553398 0.90291262 0.83495146 0.90291262 0.9223301\n",
            " 0.83495146 0.87378641]\n",
            "\n",
            "\n",
            "=== Mean Accuracy Score ===\n",
            "Mean Accuracy Score - ON Text:  0.8734736743838687\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1cOBadYIKKc"
      },
      "source": [
        "(2) Warpper Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Svoq8-IN-p"
      },
      "source": [
        "  Model (1) Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset_w=combined_train.copy()"
      ],
      "metadata": {
        "id": "_m1AEO3eOlv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(trainset_w, y)\n",
        "\n",
        "model = SelectFromModel(rfc, prefit=True)\n",
        "\n",
        "X_warp_rfc = model.transform(trainset_w)\n",
        "X_warp_rfc_SelectedFeatures= pd.DataFrame(X_warp_rfc)\n",
        "\n",
        "print(X_warp_rfc_SelectedFeatures)\n",
        "\n",
        "cv_score = cross_val_score(rfc, X_warp_rfc_SelectedFeatures, y, cv=20, scoring=\"accuracy\")\n",
        "print(\"=== All Accuracy Scores(SelectFromModel) ===\")\n",
        "print(cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean Accuracy Score(SelectFromModel) ===\")\n",
        "print(\"Mean Accuracy Score - ON Text: \",cv_score.mean())\n",
        "print('\\n')\n",
        "#export_csv= X_new_SelectedFeatures.to_csv(r'/gdrive/My Drive/CIS508-FALL2020/PT5B/X_new_SelectedFeatures.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOGF2eAhMK-o",
        "outputId": "d9456e47-fdd8-4cf7-b58a-567f005b83ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0    1         2       3          4   ...   45   46   47   48   49\n",
            "0        1.0  1.0  38000.00  229.64  24.393333  ...  0.0  1.0  0.0  1.0  0.0\n",
            "1        6.0  2.0  29616.00   75.29  49.426667  ...  1.0  0.0  1.0  0.0  1.0\n",
            "2        8.0  0.0  19732.80   47.25  50.673333  ...  0.0  0.0  1.0  0.0  1.0\n",
            "3       11.0  2.0     96.33   59.01  56.473333  ...  0.0  1.0  0.0  0.0  1.0\n",
            "4       14.0  2.0  52004.80   28.14  25.140000  ...  1.0  1.0  0.0  1.0  0.0\n",
            "...      ...  ...       ...     ...        ...  ...  ...  ...  ...  ...  ...\n",
            "2065  3821.0  0.0  78851.30   29.04  48.373333  ...  0.0  0.0  1.0  0.0  1.0\n",
            "2066  3822.0  1.0  17540.70   36.20  62.786667  ...  0.0  1.0  0.0  0.0  1.0\n",
            "2067  3823.0  0.0  83891.90   74.40  61.020000  ...  1.0  1.0  0.0  0.0  1.0\n",
            "2068  3824.0  2.0  28220.80   38.95  38.766667  ...  0.0  0.0  1.0  0.0  1.0\n",
            "2069  3825.0  0.0  28589.10  100.28  15.600000  ...  0.0  0.0  1.0  0.0  1.0\n",
            "\n",
            "[2070 rows x 50 columns]\n",
            "=== All Accuracy Scores(SelectFromModel) ===\n",
            "[0.78846154 0.89423077 0.84615385 0.90384615 0.875      0.92307692\n",
            " 0.85576923 0.81730769 0.85576923 0.91346154 0.90291262 0.91262136\n",
            " 0.95145631 0.81553398 0.89320388 0.85436893 0.9223301  0.95145631\n",
            " 0.87378641 0.91262136]\n",
            "\n",
            "\n",
            "=== Mean Accuracy Score(SelectFromModel) ===\n",
            "Mean Accuracy Score - ON Text:  0.8831684092606423\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model (2) Gradient Boost"
      ],
      "metadata": {
        "id": "KbG4ZS4rPxWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset_w2=combined_train.copy()"
      ],
      "metadata": {
        "id": "7tpnfXazSH4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Selection (Wrapper method)\n",
        "\n",
        "gb = GradientBoostingClassifier()\n",
        "gb.fit(trainset_w2, y)\n",
        "\n",
        "model = SelectFromModel(gb, prefit=True)\n",
        "\n",
        "X_warp_gb = model.transform(trainset_w2)\n",
        "X_warp_gb_SelectedFeatures= pd.DataFrame(X_warp_gb)\n",
        "\n",
        "print(X_warp_gb_SelectedFeatures)\n",
        "\n",
        "cv_score = cross_val_score(gb, X_warp_gb_SelectedFeatures, y, cv=20, scoring=\"accuracy\")\n",
        "print(\"=== All Accuracy Scores(SelectFromModel) ===\")\n",
        "print(cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean Accuracy Score(SelectFromModel) ===\")\n",
        "print(\"Mean Accuracy Score - ON Text: \",cv_score.mean())\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWr4MsLDMNg1",
        "outputId": "0b59a113-db1a-42c7-bd7c-faca5731695d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0    1         2       3          4   ...   12   13   14   15   16\n",
            "0        1.0  1.0  38000.00  229.64  24.393333  ...  0.0  1.0  0.0  0.0  0.0\n",
            "1        6.0  2.0  29616.00   75.29  49.426667  ...  1.0  0.0  0.0  1.0  1.0\n",
            "2        8.0  0.0  19732.80   47.25  50.673333  ...  1.0  0.0  0.0  0.0  1.0\n",
            "3       11.0  2.0     96.33   59.01  56.473333  ...  0.0  1.0  0.0  0.0  1.0\n",
            "4       14.0  2.0  52004.80   28.14  25.140000  ...  1.0  0.0  0.0  1.0  0.0\n",
            "...      ...  ...       ...     ...        ...  ...  ...  ...  ...  ...  ...\n",
            "2065  3821.0  0.0  78851.30   29.04  48.373333  ...  0.0  1.0  0.0  0.0  1.0\n",
            "2066  3822.0  1.0  17540.70   36.20  62.786667  ...  0.0  1.0  1.0  0.0  1.0\n",
            "2067  3823.0  0.0  83891.90   74.40  61.020000  ...  1.0  0.0  0.0  1.0  1.0\n",
            "2068  3824.0  2.0  28220.80   38.95  38.766667  ...  1.0  0.0  0.0  0.0  1.0\n",
            "2069  3825.0  0.0  28589.10  100.28  15.600000  ...  0.0  1.0  0.0  0.0  1.0\n",
            "\n",
            "[2070 rows x 17 columns]\n",
            "=== All Accuracy Scores(SelectFromModel) ===\n",
            "[0.74038462 0.875      0.79807692 0.83653846 0.86538462 0.86538462\n",
            " 0.90384615 0.80769231 0.83653846 0.89423077 0.90291262 0.91262136\n",
            " 0.9223301  0.82524272 0.9223301  0.86407767 0.9223301  0.9223301\n",
            " 0.82524272 0.66019417]\n",
            "\n",
            "\n",
            "=== Mean Accuracy Score(SelectFromModel) ===\n",
            "Mean Accuracy Score - ON Text:  0.8551344286781181\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Test Split 8:2\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "combined_train_K200_SelectedFeatures, y, test_size=0.2, random_state=17)"
      ],
      "metadata": {
        "id": "0OaFQklWMQqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter Method Best features\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, y_train)\n",
        "pred = rfc.predict(X_test)\n",
        "print(accuracy_score(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehMqrsFtMRQW",
        "outputId": "5138f19d-f965-459d-88c7-271c6077b5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8768115942028986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Test Split 8:2\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "X_warp_rfc_SelectedFeatures, y, test_size=0.2, random_state=17)"
      ],
      "metadata": {
        "id": "W7QGeUf3MTqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wrapper Method Best features\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, y_train)\n",
        "pred = rfc.predict(X_test)\n",
        "print(accuracy_score(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFt7MgATMX7-",
        "outputId": "c0ec6869-1c3b-4d43-a484-b503511b46b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8888888888888888\n"
          ]
        }
      ]
    }
  ]
}